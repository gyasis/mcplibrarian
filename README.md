# ğŸ“š MCP Librarian

> **"Save 97% of your tokens. Check out tools only when needed."**

**Status**: ğŸ”¬ Alpha Release (v0.1.0-alpha) | Currently supports Claude Code

Stop dumping all your tools on Claude's desk. Let the librarian fetch them on-demand.

---

## ğŸ¯ The Problem: Token Bloat & Manual Management Hell

### The Token Math That Kills Your Sessions

Let's say you have **20 MCP servers** with an average of **15 tools each**:

```
20 servers Ã— 15 tools = 300 total tools
300 tools Ã— ~250 tokens per tool schema = 75,000 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
75,000 tokens consumed BEFORE you even start!
That's 37.5% of your 200,000 token budget GONE! ğŸ˜±
```

**And you probably only need 2-3 of those tools per session.**

### The Manual Management Nightmare

But wait, you say: *"I'll just enable/disable servers as needed!"*

**Reality check**:

```
âŒ Manual MCP Management:
   1. Open Claude Code settings
   2. Navigate to MCP servers section
   3. Disable server-playwright (won't need it today)
   4. Disable server-gemini (won't need it today)
   5. Disable server-deeplake (won't need it today)
   6. ... repeat 17 more times ...
   7. Restart Claude Code
   8. Start your work

   *30 minutes later...*

   You: "Actually, I need to search my knowledge base"
   System: "deeplake-rag is disabled"
   You: *sighs* Back to settings...
   9. Re-enable server-deeplake
   10. Restart Claude Code AGAIN
   11. Lose your conversation context

   Repeat this tedious cycle 5-10 times per day! ğŸ¤¦
```

**This is exhausting, tedious, and kills your productivity.**

### Research Confirms This Is a Massive Problem

- [Anthropic's Tool Use Blog](https://www.anthropic.com/engineering/advanced-tool-use): "Front-loading all tools wastes 85% of context on tools you'll never use"
- [Cloudflare MCP Analysis](https://www.speakeasy.com/blog/how-we-reduced-token-usage-by-100x-dynamic-toolsets-v2): "Schemas represent 60-80% of token usage in static toolsets"
- [Scott Spence's Real-World Data](https://scottspence.com/posts/optimising-mcp-server-context-usage-in-claude-code): "66,000+ tokens consumed before conversation even starts"

**MCP Librarian is the better way.** âœ¨

---

## ğŸ’¡ The Solution: The Smart Librarian

**MCP Librarian** works like a real library - **no manual toggling, no restarts, just ask for what you need**:

```
âœ… MCP Librarian Approach:
   You: "I need help with research on X"
   Librarian: "Let me check that out for you..."
   Librarian: *quietly starts the right container*
   Librarian: *brings you exactly the tools you need*
   You: "Perfect! And I didn't lose my context or restart anything!"

   *30 minutes later...*

   You: "Now I need to test the UI with Playwright"
   Librarian: "On it!" *starts playwright container*
   You: "This is seamless! ğŸ‰"
```

**The token math:**

```
20 servers Ã— 1 polymorphic tool Ã— 100 tokens = 2,000 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
SAVES 73,000 tokens (97.3% reduction!)
198,000 tokens available for actual work! ğŸ‰

No settings menus. No restarts. No lost context.
Just seamless, on-demand tool access.
```

---

## ğŸ“š Project Origin Story

**How this project was born:**

I didn't notice my Claude Code sessions were consuming more and more tokens at first. But gradually, I noticed something was wrong - my sessions needed more and more token usage, and the context window was filling up super quick. I'd start a simple coding task and already be at 50% of my token budget before writing a single line of code!

After analyzing my system prompts, I discovered **66,000+ tokens were being consumed before my conversation even started** - just from MCP server tool schemas. With 80+ MCP servers in my setup, I was hitting 240,000 tokens at startup, exceeding my 200,000 token budget before I could even ask a question.

This project was born as a way to be more efficient with token usage around coding CLI tools. The library metaphor came naturally - instead of dumping all the books on your desk, a smart librarian checks out exactly what you need, when you need it.

**Current status**: Working with Claude Code
**Roadmap**: See [ROADMAP.md](ROADMAP.md) for expansion to Gemini Codex, Blocks, Goose CLI, OpenCode, and others

---

## ğŸ“– The Library Metaphor

| Manual MCP Management | MCP Librarian |
|----------------------|---------------|
| ğŸ”§ Edit config â†’ disable 17 servers â†’ restart | ğŸ’¬ Just ask for what you need |
| â±ï¸ 5 minutes to disable servers | âš¡ Instant, automatic activation |
| ğŸ”„ Need a tool? Re-enable â†’ restart â†’ lose context | ğŸ¯ Tool loaded seamlessly, keep context |
| ğŸ˜« Repeat this cycle 5-10 times per day | ğŸ˜Š Never think about it again |
| ğŸ“š All 300 tools loaded (75,000 tokens) | ğŸ“– 20 polymorphic tools (2,000 tokens) |
| âŒ 37.5% of budget wasted at startup | âœ… 99% of budget available for work |
| ğŸ¤¦ "Which servers do I need today?" | ğŸ‰ "What do you need help with?" |

---

## ğŸ—ï¸ How The Library Works

### 1. **The Catalog** (Registry)
```json
{
  "servers": {
    "deeplake-rag": {
      "friendly_name": "Research Database",
      "dewey_decimal": "rag.research.deeplake",
      "triggers": ["research", "articles", "saved"],
      "location": "docker-configs/deeplake-rag/"
    }
  }
}
```

Like a library catalog - the librarian knows where every book is, but doesn't put them all on your desk.

### 2. **The Checkout Desk** (Polymorphic Tool)
```
User: "Search my research articles for reverse prompting"
       â†“
Librarian Tool: deeplake_query("search articles for reverse prompting")
       â†“
Librarian: "Let me check that section for you..."
       â†“
Docker Container: *starts on-demand* (like fetching from stacks)
       â†“
Real Tools: retrieve_context(query="reverse prompting")
       â†“
Results: "Here's what I found in your research collection!"
```

### 3. **The Return Policy** (Auto-Stop)
```
Book checked out â†’ Used for 5 minutes â†’ Automatically returned to shelf
Tool container started â†’ Used â†’ Auto-stopped after 5 min idle
```

No more keeping 80 books on your desk "just in case" - the librarian returns them automatically!

---

## ğŸ“Š Real Example: Tool List Transformation

### Without MCP Librarian (Traditional Approach)

**Your deeplake-rag server has 6 tools**:

```json
// What Claude Code sees at startup (6 tools Ã— ~400 tokens = 2,400 tokens):
[
  {
    "name": "retrieve_context",
    "description": "Search vector database and retrieve relevant context...",
    "inputSchema": { /* 200 tokens of JSON schema */ }
  },
  {
    "name": "get_summary",
    "description": "Get summary of documents in the database...",
    "inputSchema": { /* 200 tokens of JSON schema */ }
  },
  {
    "name": "search_document_content",
    "description": "Search within document content...",
    "inputSchema": { /* 200 tokens of JSON schema */ }
  },
  {
    "name": "get_document",
    "description": "Retrieve a specific document by ID...",
    "inputSchema": { /* 200 tokens of JSON schema */ }
  },
  {
    "name": "get_fuzzy_matching_titles",
    "description": "Find documents by fuzzy title matching...",
    "inputSchema": { /* 200 tokens of JSON schema */ }
  },
  {
    "name": "list_documents",
    "description": "List all documents in the database...",
    "inputSchema": { /* 200 tokens of JSON schema */ }
  }
]

// Total: 2,400 tokens just for ONE server!
// With 20 servers: 20 Ã— 2,400 = 48,000 tokens minimum
```

### With MCP Librarian (Polymorphic Tool Approach)

**Claude Code sees 1 meta-tool instead**:

```json
// What Claude Code sees at startup (1 tool Ã— 100 tokens = 100 tokens):
[
  {
    "name": "deeplake_query",
    "description": "Search and query your DeepLake knowledge base using natural language. The librarian will handle the details.",
    "inputSchema": {
      "type": "object",
      "properties": {
        "query": {
          "type": "string",
          "description": "Natural language query (e.g., 'search for articles about reverse prompting')"
        }
      }
    }
  }
]

// Total: 100 tokens for the entire server!
// With 20 servers: 20 Ã— 100 = 2,000 tokens total
// Savings: 48,000 â†’ 2,000 = 96% reduction! ğŸ‰
```

### What Happens When You Call the Tool

**The librarian's workflow**:

```
Step 1: You call deeplake_query("search for articles about Docker")
        â†“
Step 2: Librarian analyzes your query
        "search" keyword detected â†’ needs retrieve_context tool
        â†“
Step 3: Librarian starts Docker container
        docker compose up -d mcp-deeplake-rag
        Container starts in ~1-2 seconds
        â†“
Step 4: Librarian calls the actual tool inside container
        retrieve_context(query="articles about Docker", n_results=5)
        â†“
Step 5: Results returned to you
        "Found 5 articles about Docker in your knowledge base..."
        â†“
Step 6: After 5 minutes of inactivity
        Librarian auto-stops container (returns book to shelf)
        docker compose down mcp-deeplake-rag
```

**You never see the complexity. Just seamless tool access.**

### The Token Math (20 Servers Example)

| Server | Tools | Traditional Tokens | MCP Librarian Tokens | Savings |
|--------|-------|-------------------|---------------------|---------|
| deeplake-rag | 6 | 2,400 | 100 | 2,300 (95.8%) |
| playwright | 25 | 10,000 | 100 | 9,900 (99%) |
| gemini | 12 | 4,800 | 100 | 4,700 (97.9%) |
| gmail | 18 | 7,200 | 100 | 7,100 (98.6%) |
| snowflake | 8 | 3,200 | 100 | 3,100 (96.9%) |
| ... 15 more | ~230 | 47,400 | 1,500 | 45,900 (96.8%) |
| **TOTAL** | **300+** | **75,000** | **2,000** | **73,000 (97.3%)** |

**And you never manually enable/disable a single server. Ever.**

---

## ğŸ“ The Research Behind This

### Anthropic's Findings: Front-Loading is Broken

From [Anthropic's Advanced Tool Use Engineering Blog](https://www.anthropic.com/engineering/advanced-tool-use):

> **"85% reduction in token usage while maintaining access to your full tool library"**

**The Problem They Identified:**
- Traditional systems front-load ALL tool definitions
- Most tools never used in a session
- Context window wasted on irrelevant schemas

**Their Solution (Tool Search Tool):**
- Discovers tools on-demand
- Claude only sees tools it needs for current task
- Massive token savings

**MCP Librarian implements this exact pattern!**

### Cloudflare/Speakeasy's Data: Schemas Are The Problem

From [Speakeasy's 100x Token Reduction Article](https://www.speakeasy.com/blog/how-we-reduced-token-usage-by-100x-dynamic-toolsets-v2):

> **"Schemas represent 60-80% of token usage in static toolsets"**

**Their Findings:**
```
Traditional Setup:
  - Tool calls: 100%
  - Input tokens: 100%
  - Problem: Schemas loaded for ALL tools

Dynamic Toolset (Lazy Loading):
  - Tool calls: 200% (2x more)
  - Input tokens: 4% (96% reduction!)
  - Solution: Load schemas only when needed
```

**Despite 2x more tool calls, input tokens dropped by 96%!**

**MCP Librarian uses the same lazy schema loading pattern.**

### Real-World Evidence: Scott Spence's Optimization Journey

From [Scott Spence's MCP Optimization Guide](https://scottspence.com/posts/optimising-mcp-server-context-usage-in-claude-code):

**Before Optimization:**
- 7 MCP servers
- 67,300 tokens consumed
- 33.7% of 200k context budget GONE before conversation starts

**After Optimization:**
- Disabled unused servers
- 8,551 tokens saved
- More context available for work

**MCP Librarian automates this optimization for 80+ servers!**

---

## ğŸš€ Quick Start: Set Up Your Library

### Installation (2 minutes)

```bash
git clone https://github.com/yourusername/mcp-librarian.git
cd mcp-librarian
pip install -e .
```

### Catalog Your First Book (5 minutes)

```bash
# The librarian analyzes your MCP server
python mcp-librarian.py ~/path/to/your/mcp-server/

# Output:
# ğŸ“š Cataloging server...
# âœ“ Found 6 tools (books in this collection)
# âœ“ Created library card (Docker container)
# âœ“ Added to catalog (registry)
# âœ“ Trained librarian (routing rules)
#
# Your server is ready to check out! ğŸ‰
```

### Add Library Card Info (2 minutes)

```bash
cd docker-configs/your-server/
nano docker-compose.yml

# Add your API keys (like a library card):
environment:
  API_KEY: "your-library-card-number"
```

### Visit The Library (1 minute)

```bash
# Start your library
docker compose up -d

# Test the checkout desk
echo '{"jsonrpc":"2.0","id":1,"method":"initialize",...}' | docker compose run --rm your-server
```

### Ask The Librarian (Claude Code)

```
User: "Search my research articles for machine learning"

Librarian: *checks out deeplake-rag book*
          *finds relevant articles*
          *returns book to shelf*

Result: Your research, delivered!
```

**DONE! You just saved 97% of your tokens! ğŸ“š**

---

## ğŸ“Š Token Savings Breakdown

### The Math

| Servers | Traditional (All Books on Desk) | MCP Librarian (Check Out On-Demand) | Savings |
|---------|--------------------------------|-------------------------------------|---------|
| 1 server | 3,000 tokens | 100 tokens | 2,900 (97%) |
| 10 servers | 30,000 tokens | 1,000 tokens | 29,000 (97%) |
| 80 servers | 240,000 tokens | 8,000 tokens | 232,000 (97%) |

### Real Impact

**Before (All Books Dumped on Desk):**
```
ğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ“š (80 stacks)
You: "I can't even see my assignment!"
Context: 0 tokens available ğŸ˜±
```

**After (Librarian Brings Books On-Demand):**
```
ğŸ“š (1 book checked out)
You: "Perfect! I can focus on my work!"
Context: 192,000 tokens available ğŸ‰
```

---

## ğŸ¯ How It Solves The Front-Loading Problem

### Traditional MCP: The Dump Truck Approach
```
Session Start:
  â†“
Load ALL 80 servers
  â†“
Expose ALL ~500 tools
  â†“
Consume 240,000 tokens
  â†“
Session FAILS - budget exceeded!
  â†“
User: "I can't even start! ğŸ˜­"
```

### MCP Librarian: The Smart Checkout Approach
```
Session Start:
  â†“
Load librarian catalog (80 polymorphic tools)
  â†“
Consume 8,000 tokens
  â†“
192,000 tokens available!
  â†“
User asks: "Search my research"
  â†“
Librarian: "Let me check that out for you..."
  â†“
Container starts (2 seconds)
  â†“
Tool executes
  â†“
Container auto-stops (5 min later)
  â†“
User: "Perfect! What else can you help with?"
```

**Key Difference**: Tools loaded WHEN NEEDED, not ALL AT ONCE.

---

## ğŸ›ï¸ The Library Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Claude Code (The Student)                               â”‚
â”‚ "I need help with my research assignment..."            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“š The Checkout Desk (Polymorphic Tools)                â”‚
â”‚                                                          â”‚
â”‚  deeplake_query("search research for X")                â”‚
â”‚  gemini_query("analyze this code")                      â”‚
â”‚  playwright_query("test this UI")                       â”‚
â”‚  ...80 checkout desks (one per collection)              â”‚
â”‚                                                          â”‚
â”‚  Token Cost: 100 per desk Ã— 80 desks = 8,000 tokens    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ‘¤ The Librarian (mcp-proxy.py)                         â”‚
â”‚                                                          â”‚
â”‚  Keywords detected: "search", "research"                â”‚
â”‚  â†’ Check out "Research Database" (deeplake-rag)         â”‚
â”‚  â†’ Start container (fetch from stacks)                  â”‚
â”‚  â†’ Route to retrieve_context tool                       â”‚
â”‚  â†’ Return results                                       â”‚
â”‚  â†’ Auto-return book after 5 min                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“š The Book Stacks (Docker Containers)                  â”‚
â”‚                                                          â”‚
â”‚  deeplake-rag container (sleeping)                      â”‚
â”‚  gemini-mcp container (sleeping)                        â”‚
â”‚  playwright container (sleeping)                        â”‚
â”‚  ...80 containers total                                 â”‚
â”‚                                                          â”‚
â”‚  Only started when book checked out!                    â”‚
â”‚  Auto-stopped when returned (5 min idle)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The Genius**: Claude only sees the checkout desk (8,000 tokens), not the entire library (240,000 tokens)!

---

## ğŸ“š Library Features

### Automatic Cataloging (90% Automated)
âœ… Server type detection (Python, Node.js)
âœ… Book collection analysis (tool schemas)
âœ… Dewey Decimal assignment (friendly names)
âœ… Shelf location setup (Docker configs)
âœ… Catalog entry creation (registry)
âœ… Librarian training (routing rules)

### Smart Checkout System
âœ… **Keyword triggers**: "search articles" â†’ checks out research database
âœ… **Dot notation**: `.deeplake` â†’ explicit checkout
âœ… **On-demand loading**: Container starts only when needed
âœ… **Auto-return**: Container stops after 5 min idle
âœ… **Multi-checkout**: Multiple tools can be checked out simultaneously

### Library Management
âœ… **Catalog search**: `get_server_documentation` (browse available books)
âœ… **Collection stats**: See all available servers/tools
âœ… **Activity tracking**: Monitor checkout/return cycles
âœ… **Resource limits**: Prevent too many books checked out at once

---

## ğŸ“ Two Learning Paths

### Path 1: Automated Cataloging (Quick Checkout) - 5-15 minutes
**Best for**: Fast setup, bulk cataloging

```bash
python mcp-librarian.py ~/mcp-server/
# Librarian catalogs everything automatically
```

**What gets automated**:
- Collection analysis (server type, tools)
- Shelf creation (Docker container)
- Catalog entry (registry)
- Librarian training (routing rules)

[**Full Guide**: docs/AUTOMATED_CATALOGING.md](docs/MCP_DOCKERIZE_GUIDE.md)

### Path 2: Manual Cataloging (Study Mode) - 2-3 hours
**Best for**: Learning, custom collections

```bash
# You work with the librarian to catalog manually
# Full control, deep understanding
```

**What you learn**:
- How the catalog system works
- Shelf organization patterns
- Dewey decimal assignment
- Custom routing strategies

[**Full Guide**: docs/MANUAL_CATALOGING.md](docs/MANUAL_DOCKERIZATION_GUIDE.md)

**Both paths achieve 97% token savings!**

---

## ğŸŒŸ What Makes This Different

### vs Manual Enable/Disable (The Tedious Way)
- âŒ Manual: Open settings â†’ disable 17 servers â†’ restart â†’ work â†’ realize you need a server â†’ re-enable â†’ restart AGAIN â†’ lose context
- âœ… MCP Librarian: Just work. Tools load automatically. Never restart.
- âŒ Manual: 5-10 min per configuration change
- âœ… MCP Librarian: Instant, seamless

### vs Traditional MCP (Front-Load Everything)
- âŒ Traditional: Load all 300 tools = 75,000 tokens wasted
- âœ… MCP Librarian: Load 20 polymorphic tools = 2,000 tokens used
- âŒ Traditional: 37.5% of budget gone at startup
- âœ… MCP Librarian: 99% of budget available for work

### vs lazy-mcp (Manual Config)
- âŒ lazy-mcp: Still requires manual enable/disable per session
- âœ… MCP Librarian: Fully automatic, no manual intervention
- âŒ lazy-mcp: 17-34k token savings (manual config)
- âœ… MCP Librarian: 73k token savings (90% automated)

### vs token-optimizer-mcp (Cache Optimization)
- âŒ token-optimizer: Optimizes after loading (still front-loads all tools)
- âœ… MCP Librarian: Never loads unused tools (true lazy loading)

### vs Anthropic's Tool Search Tool (Built-in)
- âŒ Tool Search: Requires compatible MCP servers
- âœ… MCP Librarian: Works with ANY MCP server via Docker wrapper

**MCP Librarian = Zero manual management + True lazy loading + 97.3% token savings**

---

## ğŸ’° The Real Cost Savings

### Token Savings: 97.3% Reduction

With **20 MCP servers** and **300 tools**, you're looking at:
- **Traditional approach**: 75,000 tokens wasted at every session start
- **MCP Librarian**: 2,000 tokens (just the polymorphic tools)
- **Savings**: 73,000 tokens per session

That's 97.3% of your context window back for actual work instead of tool schemas you'll never use.

### Time Savings: Stop The Manual Management Grind

**The old way** (manual enable/disable):
- 5-10 minutes every time you need to change which servers are enabled
- 5-10 times per day on average
- **30-100 minutes wasted daily** just managing your tools
- Lost context every time you restart
- Frustration and broken flow state

**With MCP Librarian**:
- Zero manual management
- Never restart Claude Code
- Never lose context
- Just ask for what you need - the librarian handles everything

### Setup Time: 90% Automation

**Manual dockerization** of 20 servers:
- ~2.5 hours per server Ã— 20 = **50 hours of tedious work**

**MCP Librarian automation**:
- ~9 minutes per server Ã— 20 = **3 hours total**
- 94% time savings on setup

**The bottom line**: More time coding, less time managing infrastructure. That's what MCP Librarian is all about.

---

## ğŸ“– Documentation Library

### Quick References
- [**QUICK_START.md**](QUICK_START.md) - 5-minute checkout guide
- [**PROJECT_OVERVIEW.md**](PROJECT_OVERVIEW.md) - Complete library overview

### Detailed Guides
- [**AUTOMATED_CATALOGING.md**](docs/MCP_DOCKERIZE_GUIDE.md) - Automated cataloging (15 pages)
- [**MANUAL_CATALOGING.md**](docs/MANUAL_DOCKERIZATION_GUIDE.md) - Manual cataloging (25 pages)

### Community
- [**CONTRIBUTING.md**](CONTRIBUTING.md) - Help expand the library
- [**CHANGELOG.md**](CHANGELOG.md) - Library version history
- [**SECURITY.md**](SECURITY.md) - Library security policy

---

## ğŸ¤ Join The Library

**Help us catalog more collections!**

We need:
- Example MCP server catalogs
- Custom routing patterns
- Docker optimization tips
- Documentation improvements

See [CONTRIBUTING.md](CONTRIBUTING.md) for how to help!

---

## ğŸ“œ License

MIT License - Free to use commercially

Just like a public library - free for everyone! ğŸ“š

---

## ğŸ™ Acknowledgments

**Inspired by (not backed by or affiliated with)**:
- [Anthropic's Tool Search Tool Research](https://www.anthropic.com/engineering/advanced-tool-use) - 85% reduction in token usage through dynamic loading
- [Cloudflare/Speakeasy's Dynamic Toolsets](https://www.speakeasy.com/blog/how-we-reduced-token-usage-by-100x-dynamic-toolsets-v2) - 96% reduction via lazy schemas (100x improvement)
- [Scott Spence's Optimization Journey](https://scottspence.com/posts/optimising-mcp-server-context-usage-in-claude-code) - Real-world data showing 66k+ tokens wasted at startup

**Inspiration from other MCP token optimization tools**:
- `lazy-mcp` - Manual lazy loading configuration patterns
- `token-optimizer-mcp` - Cache-based optimization approaches
- `OpenMCP` - Lazy schema loading techniques

**Special thanks to**:
- The MCP community for the Toolhost pattern
- Docker for containerization technology
- Everyone who contributed examples and feedback

**Disclaimer**: This is an independent open-source project inspired by published research and community best practices. Not officially endorsed by or affiliated with Anthropic, Cloudflare, or any mentioned organizations.

---

## ğŸš€ Get Started Now!

```bash
# Clone the library
git clone https://github.com/gyasis/mcplibrarian.git

# Catalog your first collection
cd mcplibrarian
python mcp-librarian.py ~/path/to/your/mcp-server/

# 5 minutes later: 97% token savings achieved!
```

**Stop dumping books on Claude's desk. Let the librarian help.** ğŸ“š

---

## ğŸ“ Library Hours (Support)

- **Documentation**: See [docs/](docs/) directory
- **Issues**: [GitHub Issues](https://github.com/gyasis/mcplibrarian/issues)
- **Discussions**: [GitHub Discussions](https://github.com/gyasis/mcplibrarian/discussions)

---

*The librarian is always ready to help. Just ask.* ğŸ“š

**MCP Librarian v0.1.0-alpha** | Save 97% of your tokens | Check out tools only when needed
